{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ce notebook permet de préparer la table et les variables pour réaliser le score de churn du TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "1. [Import](#sect1)\n",
    "2. [Nettoyage des données](#sect2)\n",
    "3. [Export des données pour le notebook \"ModelesPridictifChurn\"](#sect3)\n",
    "4. [Analyse descriptive sur les données normalisées](#sect4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "repertoire = \"../data/\"\n",
    "os.chdir(repertoire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import <a name=\"sect1\" ></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data -> données de score d'attrition dans le secteur des Telco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df = pd.read_csv('churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Nettoyage des données <a name=\"sect2\" ></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types des colonnes pour transformation\n",
    "feat_quali = ['Area Code']\n",
    "feat_quanti = [ 'Account Length', 'VMail Message', 'Day Mins', 'Day Calls', 'Day Charge',\n",
    "       'Eve Mins', 'Eve Calls', 'Eve Charge', 'Night Mins', 'Night Calls',\n",
    "       'Night Charge', 'Intl Mins', 'Intl Calls', 'Intl Charge',\n",
    "       'CustServ Calls']\n",
    "feat_bool = [\"Int'l Plan\",'VMail Plan']\n",
    "target = \"Churn?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area Code -> Catégorielle\n",
    "churn_df['Area Code']=churn_df['Area Code'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation de la variable Target en numérique\n",
    "churn_df.loc[churn_df['Churn?'] == \"True.\",'Churn?'] = 1\n",
    "churn_df.loc[churn_df['Churn?'] == \"False.\",'Churn?'] = 0\n",
    "\n",
    "y = churn_df['Churn?'].astype(int)\n",
    "# 14,5% de Churners\n",
    "print(y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation des booléens en Numpy Bool\n",
    "for col in feat_bool:\n",
    "        churn_df[col] = churn_df[col] == \"yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = churn_df.describe(include='all')\n",
    "stats.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyse de quelques variables catégorielles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des liens entre la variable catégorielle \"Area Code\" afin de recoder : \n",
    "# semble ne pas avoir de lien mais conservation de la colonne pour des liens non binaires\n",
    "print(pd.crosstab(churn_df['Area Code'],y, normalize='index'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# par contre les deux var qui indiquent si le client paie pour un service international ou VM sont très discriminantes\n",
    "print(pd.crosstab(churn_df[\"Int'l Plan\"],y, normalize='index'))\n",
    "print(pd.crosstab(churn_df[\"VMail Plan\"],y, normalize='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# étude du state\n",
    "print(pd.crosstab(churn_df['State'],y,normalize='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(churn_df['State'].unique())\n",
    "# 51 valeurs\n",
    "# soit on garde et on crée des dummy\n",
    "# soit on créé des regroupements \"métiers\" (non abordé dans la formation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dichotomisation des variables qualitative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les dummies\n",
    "churn_df = pd.get_dummies(churn_df,columns=feat_quali, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "# Traitement du state en  remplacant l'état par la moyenne de y dans chaque état\n",
    "# Faire ce travail c'est déjà faire un modèle simple donc il faut absolument refaire l'échantillon d'apprentissage\n",
    "#############################################################################################\n",
    "# split Apprentissage Test\n",
    "from sklearn.model_selection import train_test_split \n",
    "state_train, state_test, y_train, y_test = train_test_split(churn_df['State'],y,  test_size=0.3,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taux_reponse_state_train=pd.crosstab(state_train,y_train).apply(lambda r: r/r.sum(), axis=1)[1]\n",
    "taux_reponse_state_test=pd.crosstab(state_test,y_test).apply(lambda r: r/r.sum(), axis=1)[1]\n",
    "print(taux_reponse_state_train) # churn par état"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(taux_reponse_state_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del state_test,y_test,  taux_reponse_state_test\n",
    "del state_train\n",
    "# on remplace le state par le taux de reponse associé\n",
    "list(taux_reponse_state_train)\n",
    "# replace une liste par une liste\n",
    "churn_df['State'].replace(list(taux_reponse_state_train.index), list(taux_reponse_state_train), inplace=True)\n",
    "churn_df.rename(columns={\"State\": \"churnMoy_state\"},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppression de variables inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop=['Phone']\n",
    "churn_df = churn_df.drop(to_drop,axis=1)\n",
    "churn_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Export <a name=\"sect3\" ></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file=open(\"churn_prepared.pydata\",\"wb\")\n",
    "pickle.dump(churn_df,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Analyse descriptive <a name=\"sect4\" ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Décupage entre variables explicatives et target\n",
    "X = churn_df.drop(target, axis=1)\n",
    "y = churn_df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'abord on normalise les données afin d'avoir des analyses comparables sur la même échelle dans les box plot ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "norm=StandardScaler().fit(X) \n",
    "X_norm = norm.transform(X) \n",
    "# ou \n",
    "# X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = pd.DataFrame(X_norm)\n",
    "# on récupère les noms de col\n",
    "X_norm.columns = X.columns\n",
    "X_norm.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taux moyen de 14.4% de churners\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcul du nb de lignes et colonnes à ajouter pour la data viz\n",
    "nb_feat = len(X_norm.columns) \n",
    "n_col = 3\n",
    "n_rows = nb_feat // n_col\n",
    "if (nb_feat % n_col) > 0:\n",
    "    n_rows += 1\n",
    "\n",
    "n_col,  n_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(n_rows, n_col, figsize=(15, 30), sharey=True)\n",
    "\n",
    "r = 0\n",
    "c = 0\n",
    "for col in X_norm.columns:\n",
    "    if c < (n_col - 1):\n",
    "        sns.boxplot(ax=axes[r][c], x = y, y=X_norm[col])\n",
    "        \n",
    "    elif c == (n_col - 1):\n",
    "        sns.boxplot(ax=axes[r][c], x = y, y=X_norm[col])\n",
    "        r += 1\n",
    "    else:\n",
    "        c = 0\n",
    "        sns.boxplot(ax=axes[r][c], x = y, y=X_norm[col])\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tri croisé des var quali\n",
    "for i in (\"Int'l Plan\",\"VMail Plan\",\"Area Code_415\",\"Area Code_510\"):\n",
    "    print(pd.crosstab(X_norm[i], y, normalize=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m119"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
