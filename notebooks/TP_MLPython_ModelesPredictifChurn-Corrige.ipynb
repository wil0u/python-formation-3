{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP MODELISATION DU CHURN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rechargement des données préparées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "repertoire = \"/home/jupyter/EF-form-py-ML/data\"\n",
    "os.chdir(repertoire)\n",
    "import pickle\n",
    "file=open(\"churn_prepared.pydata\",\"rb\")\n",
    "Xy=pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churnMoy_state    float64\n",
       "Account Length    float64\n",
       "Int'l Plan        float64\n",
       "VMail Plan        float64\n",
       "VMail Message     float64\n",
       "Day Mins          float64\n",
       "Day Calls         float64\n",
       "Day Charge        float64\n",
       "Eve Mins          float64\n",
       "Eve Calls         float64\n",
       "Eve Charge        float64\n",
       "Night Mins        float64\n",
       "Night Calls       float64\n",
       "Night Charge      float64\n",
       "Intl Mins         float64\n",
       "Intl Calls        float64\n",
       "Intl Charge       float64\n",
       "CustServ Calls    float64\n",
       "area__415         float64\n",
       "area__510         float64\n",
       "Churn?               bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# données sont centrées réduites\n",
    "Xy.describe()\n",
    "Xy.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= Xy.drop('Churn?',axis=1)\n",
    "y=Xy['Churn?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charger les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jupyter/EF-form-py-ML/modules\")\n",
    "sys.path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from fonctions_metrics import lift\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score,roc_auc_score,roc_curve,auc\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Apprentissage Test\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Xy['Churn?'], test_size=0.4,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETRER LE MODELE REG PENALISEE\n",
    "Choisir ridge (L2) ou lasso (L1) ou elasticnet, avec la classe LogisticRegression\n",
    "Définir une grille d'hyper param pour C\n",
    "et utliser GridSearchCV pour la balayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regression logistique avec pénalité lasso et grid search\n",
    "#### on cherche par CV le meilleur C (1/alpha) le coef de regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.05}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = [{\"C\":[0.001,0.005,0.01,0.025,0.05,0.075,0.1]}]\n",
    "# Instancie le modele LASSO : construction classe\n",
    "lr=LogisticRegression(penalty='l1',solver='liblinear')\n",
    "# Grid Search : on indique le modele et la grille de param\n",
    "modeleLassoCV = GridSearchCV (lr,param,cv = 4,n_jobs=-1,scoring='roc_auc')\n",
    "modeleLassoCV = modeleLassoCV.fit(X_train,y_train)\n",
    "modeleLassoCV.best_params_\n",
    "#{'C': 0.0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Je constate que le meilleur modeles est 0.05 donc je le reinstancie \n",
    "model_LogitL1 =LogisticRegression(penalty='l1',solver='liblinear',C=0.05)\n",
    "# appliquer la méthode fit() : apprend sur les données de TRAIN\n",
    "model_LogitL1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17675018976637946,\n",
       " 0.0,\n",
       " 0.46274789799405985,\n",
       " -0.2301937156620589,\n",
       " 0.0,\n",
       " 0.09845888354394194,\n",
       " 0.0,\n",
       " 0.4128113632841629,\n",
       " 0.20040736653217395,\n",
       " 0.0,\n",
       " 0.02649549505863574,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.105609792790601,\n",
       " 0.09788123415582668,\n",
       " 0.4731083730768118,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# récupérer les coef\n",
    "coef=list(model_LogitL1.coef_[0]) # c un array2d, \n",
    "len(coef) # il y a 20 \n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# combien d'élemnts non nuls ?\n",
    "feature_0= list(map(lambda x: x==0.0, coef)) #print(feature_0)\n",
    "print(feature_0.count(True)) # 6\n",
    "del feature_0\n",
    "\n",
    "# PLus on baisse C, plus de colonnes s'annulent (0)\n",
    "# print(pd.DataFrame({'Coefficients': list(reg.coef_)}, list(X.columns.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction des probabilités de 1 avec    model_LogitL1.predict_proba(X)\n",
    "# Colonne 1 signifie la seconde modalité du vecteur soit la proba Churn=1\n",
    "probas_test = model_LogitL1.predict_proba(X_test)[:,1]\n",
    "probas_train = model_LogitL1.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8748125937031485\n",
      "0.8524262131065533\n"
     ]
    }
   ],
   "source": [
    "# score: accuracy taux de bien classé global au cutoff de 0.5\n",
    "print(model_LogitL1.score(X_test, y_test))\n",
    "print(model_LogitL1.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8160062954947865\n",
      "0.8444328922495273\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "print(roc_auc_score(y_train,probas_train))\n",
    "print(roc_auc_score(y_test,probas_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lift at 10 percent : 3.31\n",
      "3.31\n",
      "lift at 10 percent : 4.18\n",
      "4.18\n"
     ]
    }
   ],
   "source": [
    "from fonctions_metrics import lift\n",
    "#compute lift at 10%#\n",
    "print(lift(probas_train,X_train,y_train))\n",
    "print(lift(probas_test,X_test,y_test))\n",
    "\n",
    "# Le lift à 10% : je prend les 10% plus fortes proba de churn (individus les plus risqués),\n",
    "# taux de churn / taux de churn moyen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lift at 5 percent : 3.55\n",
      "3.55\n",
      "lift at 5 percent : 4.67\n",
      "4.67\n"
     ]
    }
   ],
   "source": [
    "#compute lift at 5%\n",
    "print(lift(probas_train,X_train,y_train,p=5))\n",
    "print(lift(probas_test,X_test,y_test,p=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lift at 5 percent : 4.67\n",
      "lift at 10 percent : 4.18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': 'Score Lasso',\n",
       "  'AUC_test': 0.844,\n",
       "  'lift at 5': 4.67,\n",
       "  'lift at 10': 4.18}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ENR LES RESULTATS DANS UN DICTIONNAIRE POUR POUVOIR COMPARER\n",
    "model='Score Lasso'\n",
    "# métriques (liste de dictionnaires)\n",
    "metriques = [{'model':model,'AUC_test':round(roc_auc_score(y_test,probas_test),3),'lift at 5':lift(probas_test,X_test,y_test,p=5),'lift at 10':lift(probas_test,X_test,y_test,p=10)}]\n",
    "metriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[796 354]\n",
      " [ 29 155]]\n",
      "col_0          0         1\n",
      "Churn?                    \n",
      "False   0.692174  0.307826\n",
      "True    0.157609  0.842391\n",
      "col_0          0         1\n",
      "Churn?                    \n",
      "False   0.964848  0.695481\n",
      "True    0.035152  0.304519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Fidèles       0.96      0.69      0.81      1150\n",
      "    Churners       0.30      0.84      0.45       184\n",
      "\n",
      "    accuracy                           0.71      1334\n",
      "   macro avg       0.63      0.77      0.63      1334\n",
      "weighted avg       0.87      0.71      0.76      1334\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Fidèles       0.88      0.99      0.93      1150\n",
      "    Churners       0.68      0.17      0.28       184\n",
      "\n",
      "    accuracy                           0.87      1334\n",
      "   macro avg       0.78      0.58      0.60      1334\n",
      "weighted avg       0.85      0.87      0.84      1334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mat de confusion à un cutoff donné\n",
    "pred = (probas_test > 0.14).astype(int)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "# parmi les vrais 1 82% sont bien prédits\n",
    "print(pd.crosstab(y_test,pred).apply(lambda r: r/r.sum(), axis=1))\n",
    "# parmi les predits 1 34% sont des vrais positifs\n",
    "print(pd.crosstab(y_test,pred).apply(lambda r: r/r.sum(), axis=0))\n",
    "\n",
    "target_names = ['Fidèles','Churners']\n",
    "\n",
    "# métriques au cutoff donné\n",
    "print(classification_report(y_test,pred, target_names=target_names))\n",
    "# métriques au cutoff par défaut\n",
    "print(classification_report(y_test,model_LogitL1.predict(X_test), target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETRER LE MODELE REG PENALISEE ELASTICNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.015}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Régression logistique elastic net : SGDClassifier : loss = log --> logistique\n",
    "#### penalty = \"elasticnet\"\n",
    "#### alpha entre 1 et 1000 , et l1_ratio entre 0 et 1\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#Defaults to ‘hinge’, which gives a linear SVM. The ‘log’ loss gives logistic regression, a probabilistic classifier. \n",
    "#l1_ratio : float\n",
    "#The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1. l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1. Defaults to 0.15\n",
    "\n",
    "param = [{\"alpha\":(0.001,0.01,0.015,0.025,0.004,0.05,0.075,0.1,0.2)} ]\n",
    "sgdElasticAUCnow = GridSearchCV (SGDClassifier(loss=\"log\", penalty=\"elasticnet\",l1_ratio=0.25,class_weight=None), param, cv = 4,n_jobs=4,scoring='roc_auc')\n",
    "\n",
    "cvelasticnet = sgdElasticAUCnow.fit(X_train,y_train)\n",
    "cvelasticnet.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2345409 ,  0.0348406 ,  0.49181115, -0.29243987,  0.        ,\n",
       "         0.29740455,  0.        ,  0.2976106 ,  0.15599409,  0.04143732,\n",
       "         0.1556868 ,  0.02746298,  0.        ,  0.02669302,  0.07585822,\n",
       "        -0.1731572 ,  0.0782818 ,  0.52338825,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet = SGDClassifier(loss=\"log\", penalty=\"elasticnet\", alpha=0.015,l1_ratio=0.25,class_weight=None)\n",
    "# Apprentissage du modele\n",
    "elasticnet.fit(X_train,y_train)\n",
    "elasticnet.coef_\n",
    "  #compute lift at 10%#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser les résultats et les performances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction des probabilités de 1 avec    model_LogitL1.predict_proba(X)\n",
    "probas_test = elasticnet.predict_proba(X_test)[:,1]\n",
    "probas_train = elasticnet.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8151072201455833\n",
      "0.8438468809073724\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "print(roc_auc_score(y_train,probas_train))\n",
    "print(roc_auc_score(y_test,probas_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lift at 5 percent : 4.78\n",
      "lift at 10 percent : 4.13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': 'Score Lasso',\n",
       "  'AUC_test': 0.844,\n",
       "  'lift at 5': 4.67,\n",
       "  'lift at 10': 4.18},\n",
       " [{'model': 'Score elasticnet',\n",
       "   'AUC_test': 0.844,\n",
       "   'lift at 5': 4.78,\n",
       "   'lift at 10': 4.13}]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AJOUTE LES RESULTATS\n",
    "model='Score elasticnet'\n",
    "# métriques (liste de dictionnaires)\n",
    "metriques.append([{'model':model,'AUC_test':round(roc_auc_score(y_test,probas_test),3),'lift at 5':lift(probas_test,X_test,y_test,p=5),'lift at 10':lift(probas_test,X_test,y_test,p=10)}])\n",
    "metriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETRER LE MODELE RANDOMFOREST\n",
    "Tester un modle light peu profond et un modele complexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple randomforest avec des rbres peu profonds\n",
    "rf_light = RandomForestClassifier(     n_estimators = 300,\n",
    "                                       criterion = \"gini\",\n",
    "                                       max_features = \"sqrt\",\n",
    "                                       max_depth = 4,\n",
    "                                       min_samples_split = 40,\n",
    "                                       min_samples_leaf = 30,                                                                           \n",
    "                                       bootstrap = True,\n",
    "                                       oob_score = True,\n",
    "                                       n_jobs = -1, # coeurs\n",
    "                                       random_state = 1234,\n",
    "                                       class_weight=\"balanced\"\n",
    "                                     )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec des arbres profonds et dont les feuilles avec 5 ind min\n",
    "# on bloque à 100 feuilles max\n",
    "rf_complex= RandomForestClassifier(     n_estimators = 300,\n",
    "                                       criterion = \"gini\",\n",
    "                                       max_features = \"sqrt\",\n",
    "                                       max_depth = 8,\n",
    "                                       min_samples_split = 10,\n",
    "                                       min_samples_leaf = 5,                                                                           \n",
    "                                       max_leaf_nodes = 100,\n",
    "                                       bootstrap = True,\n",
    "                                       oob_score = True,\n",
    "                                       n_jobs = -1, # coeurs\n",
    "                                       random_state = 1234,\n",
    "                                       class_weight=\"balanced\"\n",
    "                                     )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=8, max_features='sqrt',\n",
       "                       max_leaf_nodes=100, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=10,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "                       n_jobs=-1, oob_score=True, random_state=1234, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apprentissage du modele avec methode fit\n",
    "rf_light.fit(X_train,y_train)\n",
    "rf_complex.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSER LES RESULTATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Day Charge</th>\n",
       "      <td>0.162421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustServ Calls</th>\n",
       "      <td>0.157764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day Mins</th>\n",
       "      <td>0.147565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Int'l Plan</th>\n",
       "      <td>0.083224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eve Charge</th>\n",
       "      <td>0.055548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eve Mins</th>\n",
       "      <td>0.054607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intl Charge</th>\n",
       "      <td>0.036346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intl Calls</th>\n",
       "      <td>0.033874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intl Mins</th>\n",
       "      <td>0.033751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VMail Message</th>\n",
       "      <td>0.032118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Night Mins</th>\n",
       "      <td>0.030537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Night Charge</th>\n",
       "      <td>0.027971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churnMoy_state</th>\n",
       "      <td>0.027677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day Calls</th>\n",
       "      <td>0.026004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account Length</th>\n",
       "      <td>0.023521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VMail Plan</th>\n",
       "      <td>0.020553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eve Calls</th>\n",
       "      <td>0.020524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Night Calls</th>\n",
       "      <td>0.019599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area__415</th>\n",
       "      <td>0.003517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area__510</th>\n",
       "      <td>0.002878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Importance\n",
       "Day Charge        0.162421\n",
       "CustServ Calls    0.157764\n",
       "Day Mins          0.147565\n",
       "Int'l Plan        0.083224\n",
       "Eve Charge        0.055548\n",
       "Eve Mins          0.054607\n",
       "Intl Charge       0.036346\n",
       "Intl Calls        0.033874\n",
       "Intl Mins         0.033751\n",
       "VMail Message     0.032118\n",
       "Night Mins        0.030537\n",
       "Night Charge      0.027971\n",
       "churnMoy_state    0.027677\n",
       "Day Calls         0.026004\n",
       "Account Length    0.023521\n",
       "VMail Plan        0.020553\n",
       "Eve Calls         0.020524\n",
       "Night Calls       0.019599\n",
       "area__415         0.003517\n",
       "area__510         0.002878"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importance des variables\n",
    "df=pd.DataFrame(rf_complex.feature_importances_,X_train.columns.values)\n",
    "df.columns=['Importance']\n",
    "df.sort_values(by='Importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction des probabilités de 1 ( array2d ) avec fonction predict_proba\n",
    "probas_test = rf_light.predict_proba(X_test)[:,1]\n",
    "probas_train = rf_light.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.922242770017706\n",
      "0.8936814744801512\n"
     ]
    }
   ],
   "source": [
    "#AUC sur train et test avec roc_auc_score\n",
    "print(roc_auc_score(y_train,probas_train))\n",
    "print(roc_auc_score(y_test,probas_test))\n",
    "# un peu de surapprentissage mais peu ce qui est normal car ce sont des arbres peu profonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lift at 10 percent : 5.75\n",
      "5.75\n",
      "lift at 10 percent : 5.54\n",
      "5.54\n"
     ]
    }
   ],
   "source": [
    "print(lift(probas_train,X_train,y_train))\n",
    "print(lift(probas_test,X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lift at 5 percent : 6.41\n",
      "lift at 10 percent : 5.54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': 'Score Lasso',\n",
       "  'AUC_test': 0.844,\n",
       "  'lift at 5': 4.67,\n",
       "  'lift at 10': 4.18},\n",
       " [{'model': 'Score elasticnet',\n",
       "   'AUC_test': 0.845,\n",
       "   'lift at 5': 4.67,\n",
       "   'lift at 10': 4.13}],\n",
       " [{'model': 'rf light',\n",
       "   'AUC_test': 0.894,\n",
       "   'lift at 5': 6.41,\n",
       "   'lift at 10': 5.54}]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AJOUTE LES RESULTATS\n",
    "model='rf light'\n",
    "# métriques (liste de dictionnaires)\n",
    "metriques.append([{'model':model,'AUC_test':round(roc_auc_score(y_test,probas_test),3),'lift at 5':lift(probas_test,X_test,y_test,p=5),'lift at 10':lift(probas_test,X_test,y_test,p=10)}])\n",
    "metriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction des probabilités de 1 ( array2d ) avec fonction predict_proba\n",
    "probas_test = rf_complex.predict_proba(X_test)[:,1]\n",
    "probas_train = rf_complex.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9906925044265198\n",
      "0.9094092627599244\n"
     ]
    }
   ],
   "source": [
    "#AUC sur train et test avec roc_auc_score\n",
    "print(roc_auc_score(y_train,probas_train))\n",
    "print(roc_auc_score(y_test,probas_test))\n",
    "# ! Surapprentissage ce qui est normal car ce sont des arbres profonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lift at 5 percent : 7.07\n",
      "lift at 10 percent : 6.58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': 'Score Lasso',\n",
       "  'AUC_test': 0.844,\n",
       "  'lift at 5': 4.67,\n",
       "  'lift at 10': 4.18},\n",
       " [{'model': 'Score elasticnet',\n",
       "   'AUC_test': 0.844,\n",
       "   'lift at 5': 4.78,\n",
       "   'lift at 10': 4.13}],\n",
       " [{'model': 'rf complex',\n",
       "   'AUC_test': 0.909,\n",
       "   'lift at 5': 7.07,\n",
       "   'lift at 10': 6.58}]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AJOUTE LES RESULTATS\n",
    "model='rf complex'\n",
    "# métriques (liste de dictionnaires)\n",
    "metriques.append([{'model':model,'AUC_test':round(roc_auc_score(y_test,probas_test),3),'lift at 5':lift(probas_test,X_test,y_test,p=5),'lift at 10':lift(probas_test,X_test,y_test,p=10)}])\n",
    "metriques\n",
    "# conclusion  le modele RF est plus predictif mais moins confiance dans sa capacité à etre robuste à moyen terme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETRER LE MODELE BOOSTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### sans randomisation (subsample=1.0 = on prend tt l'échantillon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_noRand05=GradientBoostingClassifier(loss='deviance', learning_rate=0.05,\n",
    "                           n_estimators=500,\n",
    "                           subsample=1.0, min_samples_split=20, min_samples_leaf=10,\n",
    "                           max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprentissage du modele\n",
    "gbt_noRand05.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# étude du nb iterations optimal en affichant la fonction de perte sur lech test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter=500\n",
    "iter = np.arange(niter) + 1\n",
    "test_deviance = np.zeros((niter,), dtype=np.float64)\n",
    "# staged_decision_functio : décision fonction à chaque iteration\n",
    "for i, y_pred in enumerate(gbt_noRand05.staged_decision_function(X_test)):\n",
    "    # clf.loss_ assumes that y_test[i] in {0, 1}\n",
    "    test_deviance[i] = gbt_noRand05.loss_(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Erreur sur le test (evolution deviance)\n",
    "plt.plot(iter,test_deviance,label='Test',color='darkorange')\n",
    "        # min vers 100 \n",
    "# Erreur sur apprentissage (evolution deviance)\n",
    "plt.plot(iter,gbt_noRand05.train_score_,label='Apprentissage',color='navy')    \n",
    "# Diminution de l'erreur rapport modele precedant (par rapport au oob)\n",
    "#plt.plot(iter,gbt_noRand05.oob_improvement_)\n",
    "plt.legend(loc=\"upper right\", fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction des probabilités de 1 , array2d\n",
    "probas_test = gbt_noRand05.predict_proba(X_test)[:,1]\n",
    "probas_train = gbt_noRand05.predict_proba(X_train)[:,1]\n",
    "  #AUC\n",
    "roc_auc_score(y_train,probas_train)\n",
    "# 1\n",
    "roc_auc_score(y_test,probas_test)\n",
    "# AUC 0.91 sur test\n",
    "\n",
    "#compute lift at 10%#\n",
    "lift(probas_train,X_train,y_train)\n",
    "lift(probas_test,X_test,y_test)\n",
    "# x 7.6\n",
    "#compute lift at 5%\n",
    "lift(probas_test,X_test,y_test,p=5)\n",
    "# 10.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### algo avec randomisation subsample=0.5 et max_feature = racine(nb variable)\n",
    "###########\n",
    "gbt_Rand=GradientBoostingClassifier(loss='deviance', learning_rate=0.05,\n",
    "                           n_estimators=500,\n",
    "                           subsample=0.5, min_samples_split=30, min_samples_leaf=20,\n",
    "                           min_weight_fraction_leaf=0.005,\n",
    "                           max_depth=3,max_leaf_nodes=12,max_features=\"sqrt\")\n",
    "# Apprentissage du modele\n",
    "gbt_Rand.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter=500\n",
    "iter = np.arange(niter) + 1\n",
    "test_deviance = np.zeros((niter,), dtype=np.float64)\n",
    "# staged_decision_functio : décision fonction à chaque iteration\n",
    "for i, y_pred in enumerate(gbt_Rand.staged_decision_function(X_test)):\n",
    "    # clf.loss_ assumes that y_test[i] in {0, 1}\n",
    "    test_deviance[i] = gbt_Rand.loss_(y_test, y_pred)\n",
    "\n",
    "# negative cumulative sum of oob improvements (améliration de l'erreur)\n",
    "#out-of-bag (OOB) estimates can be a useful heuristic to estimate the “optimal” number of boosting iterations. OOB estimates are almost identical to cross-validation estimates but they can be computed on-the-fly without the need for repeated model fitting. OOB estimates are only available for Stochastic Gradient Boosting (i.e. subsample < 1.0), the estimates are derived from the improvement in loss based on the examples not included in the bootstrap sample (the so-called out-of-bag examples). The OOB estimator is a pessimistic estimator of the true test loss, but remains a fairly good approximation for a small number of trees.\n",
    "cumsum = -np.cumsum(gbt_Rand.oob_improvement_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(iter,test_deviance,label='Test',color='darkorange')\n",
    "plt.plot(iter,gbt_Rand.train_score_,label='Apprentissage',color='navy')    \n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(iter,cumsum,label='OOB loss')\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(iter,gbt_Rand.oob_improvement_,label='amélioration loss sur OOB')\n",
    "        # min vers 100 \n",
    "# Erreur sur apprentissage (evolution deviance)\n",
    "plt.plot(iter,gbt_noRand05.train_score_,label='Apprentissage',color='navy')    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       # min vers 100\n",
    "     #   pred_at_eachstage=enumerate(gbt_Rand.staged_predict(X_testCR),100)\n",
    "gbt_Rand=GradientBoostingClassifier(loss='deviance', learning_rate=0.05,\n",
    "                           n_estimators=150,\n",
    "                           subsample=0.5, min_samples_split=30, min_samples_leaf=20,\n",
    "                           min_weight_fraction_leaf=0.005,\n",
    "                           max_depth=3,max_leaf_nodes=12,max_features=\"sqrt\")\n",
    "# Apprentissage du modele\n",
    "gbt_Rand.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "probas_test = gbt_Rand.predict_proba(X_test)[:,1]\n",
    "probas_train = gbt_Rand.predict_proba(X_train)[:,1]\n",
    "  #AUC\n",
    "roc_auc_score(y_train,probas_train)\n",
    "# 0,979\n",
    "roc_auc_score(y_test,probas_test)\n",
    "# AUC 0.89 sur test\n",
    "\n",
    "#compute lift at 10%#\n",
    "lift(probas_train,X_train,y_train)\n",
    "lift(probas_test,X_test,y_test)\n",
    "# x 7.3\n",
    "#compute lift at 5%\n",
    "lift(probas_test,X_test,y_test,p=5)\n",
    "# 9.1"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
