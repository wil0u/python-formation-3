{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédire le prix de l'immobilier\n",
    "Le jeu de données décrit des biens avec des variables quantitatives et qualitatives ainsi que le prix de vente\n",
    "Introduction à la régression linéaire et aux variantes (rég. pénalisée comme lasso)\n",
    "Le prix de vente va etre modélisé par les autres variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "repertoire = \"../data\"\n",
    "os.chdir(repertoire)\n",
    "\n",
    "#https://www.kaggle.com/code/michaelfumery/exercice-pr-diction-de-prix-de-maison/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données : apprentissage, appli, éch. de submission kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_submission = pd.read_csv(\"prix_immo\\\\sample_submission.csv\")\n",
    "\n",
    "train = pd.read_csv(\"prix_immo\\\\train.csv\") # jeu de données d'entrainement (avec le prix)\n",
    "appli = pd.read_csv(\"prix_immo\\\\test.csv\") # jeu de données où le prix est inconnu (à prédire)\n",
    "#création d'une copie de chaque dataset\n",
    "appli_copy  = appli.copy()\n",
    "train_copy  = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiser premieres lignes\n",
    "train_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_copy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "il y a 81 colonnes dont 79 variables X (features), 1 colonne ID et la variable cible \"SalePrice\".\n",
    "La variable ID pourrait être supprimée\n",
    "Nous allons concaténer les 2 datasets train et appli afin de procéder aux memes transformations sur les deux jeux de données (une colonne est créée pours identifier Train vs appli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['train']  = 1\n",
    "appli_copy['train']  = 0\n",
    "data_full = pd.concat([train_copy, appli_copy], axis=0,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons calculer le pourcentage de valeurs manquantes pour chaque variable. On voit ci dessus que certaines var. ont un nombre non null faible. (MiscFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NULL = [(c, data_full[c].isna().mean()*100) for c in data_full]\n",
    "df_NULL = pd.DataFrame(df_NULL, columns=[\"Colonne\", \"Taux de NULL\"])\n",
    "df_NULL.sort_values(\"Taux de NULL\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variables avec plus de 10% de NULL : suppression\n",
    "\n",
    "#df_NULL = df_NULL.drop(['SalePrice'],axis=0)\n",
    "\n",
    "df_NULL = df_NULL[df_NULL[\"Taux de NULL\"] > 10]\n",
    "\n",
    "df_NULL = df_NULL[df_NULL[\"Colonne\"] != 'SalePrice'] # on ne supprime pas la cible\n",
    "\n",
    "df_NULL.sort_values(\"Taux de NULL\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_NULL_features = df_NULL[\"Colonne\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_NULL_features = list(df_NULL.Colonne)\n",
    "\n",
    "data_full = data_full.drop(list_NULL_features,axis=1)\n",
    "data_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NULL = [(c, data_full[c].isna().mean()*100) for c in data_full]\n",
    "df_NULL = pd.DataFrame(df_NULL, columns=[\"Colonne\", \"Taux de NULL\"])\n",
    "df_NULL.sort_values(\"Taux de NULL\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering : préparation des données pour la modélisation\n",
    "On va traiter les val. manquantes\n",
    "On traite differemment les var. numeriques (quantitatives) et les categorielles (qualitatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = data_full.select_dtypes(include=['object'])\n",
    "numerical_features = data_full.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables catégorielles :\n",
    "print(\"Nombre de variables  :\",categorical_features.shape[1])\n",
    "print(\"\\nNombre de valeurs nulles :\\n\",categorical_features.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après consultation de la description des fichiers de données, nous allons compléter les valeurs nulles des categoricla features ainsi :\n",
    "\n",
    "    BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, GarageType, GarageFinish, GarageQual, FireplaceQu, GarageCond seront complétés avec la valeur \"None\",\n",
    "    les autres variables avec leur propre valeur la plus fréquente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_None = ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1','BsmtFinType2', 'GarageType', 'GarageFinish', 'GarageQual','GarageCond']\n",
    "categorical_features[fill_None]= categorical_features[fill_None].fillna('None')\n",
    "fill_other = ['MSZoning','Utilities','Exterior1st','Exterior2nd','Electrical','KitchenQual','Functional','SaleType']\n",
    "categorical_features[fill_other] = categorical_features[fill_other].fillna(categorical_features.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features.info()\n",
    "# LEs var. catégorielles sont traitées : 2919 val. non nulles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nous allons pouvoir gérer les manquants sur les var. quantitatives:\n",
    "\n",
    "Les numerical features (hors SalePrice) avec le plus grand nombre de NULL sont les suivantes :\n",
    "    LotFrontage\n",
    "    GarageYrBlt\n",
    "\n",
    "Nous allons utiliser la médiane de ces variables pour compléter les valeurs nulles. Pour les autres variables, les valeurs nulles seront complétées à 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features['GarageYrBlt'] = numerical_features['GarageYrBlt'].fillna(numerical_features['GarageYrBlt'].median())\n",
    "#numerical_features['LotFrontage'] = numerical_features['LotFrontage'].fillna(numerical_features['LotFrontage'].median())\n",
    "numerical_features['MasVnrArea'] = numerical_features['MasVnrArea'].fillna(numerical_features['MasVnrArea'].median())\n",
    "numerical_features = numerical_features.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering : variables enrichies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Age de la maison\n",
    "numerical_features['HouseAge'] = numerical_features['YrSold'] - numerical_features['YearBuilt']\n",
    "# Age depuis la dernière rénovation    \n",
    "numerical_features['RemodAge'] = numerical_features['YrSold'] - numerical_features['YearRemodAdd']\n",
    "\n",
    "\n",
    "# Surface habitable totale\n",
    "numerical_features['TotalSF'] = numerical_features['TotalBsmtSF']+ numerical_features['GrLivArea']+ numerical_features['GarageArea']\n",
    "# Surface habitable au sol\n",
    "numerical_features['1st2ndFlrSF'] = numerical_features['1stFlrSF'] + numerical_features['2ndFlrSF']   \n",
    "\n",
    "# Lot Utilization: Ratio of total square footage to lot area\n",
    "numerical_features['LotRatio'] = numerical_features['TotalSF'] / numerical_features['LotArea']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garage Score: Quality * Condition of garage (numeric mapping)\n",
    "qual_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'None': 0}\n",
    "numerical_features['GarageScore'] = (categorical_features['GarageQual'].map(qual_map, na_action='ignore').fillna(0) * categorical_features['GarageCond'].map(qual_map, na_action='ignore').fillna(0))\n",
    "\n",
    "categorical_features=categorical_features.drop(['GarageQual','GarageCond'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering : encoder les variables catégorielles\n",
    "En effet, la modélisation suppose que les variables soient représentées par des nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pandas get dummies crée des variables binaires pour chaque modalité d'une variable catégorielle\n",
    "\n",
    "categorical_features = pd.get_dummies(categorical_features, drop_first=True)\n",
    "\n",
    "categorical_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLE POUR L'APPRENTISSAGE (X, Y )\n",
    "L'usage est de séparer les données en un jeu X contenant les features et un vecteur col y contenant juste la cible\n",
    "Il est obligatoire en ML de séparer en un ech de train et de appli, le appli n'est pas utilisé dans l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([numerical_features,categorical_features], axis=1,sort=False)\n",
    "# Les va. manquantes sur le prix de vente ne peuvent pas etre imputées, il faut les supprimer\n",
    "df_final = df_final[df_final['SalePrice'] >0 ]\n",
    "df_final.shape\n",
    "\n",
    "X = df_final.drop(['SalePrice','train','Id'], axis=1)\n",
    "y = df_final['SalePrice']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation en un jeu d'entrainement et un jeu d'application (test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y, train_size=0.75, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modele naif : prédire le prix par la moyenne des prix sur l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_prix_mean = np.mean(y_train)\n",
    "m1_prix_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ RMSE = \\sqrt{ \\frac {\\sum (obs - pred)^2 }{n} } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_m1_train = np.sqrt(np.sum((y_train - m1_prix_mean)**2) / X_train.shape[0])\n",
    "RMSE_m1_valid = np.sqrt(np.sum((y_valid - m1_prix_mean)**2) / X_valid.shape[0])\n",
    "\n",
    "print(RMSE_m1_train,RMSE_m1_valid)\n",
    "# le RMSE du modèle \"naïf\" qui prédit toujours la moyenne est de 80 k $ et 77 k $ sur le jeu de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction de calculs des metriques importantes MAE, MSE, MAPE, RMSE\n",
    "def metrics_regression(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    diff = y_true - y_pred\n",
    "    mae = np.mean(abs(diff))\n",
    "    mse = np.mean(diff**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs(diff / y_true)) * 100\n",
    "    dict_metrics = {\"Métrique\":[\"MAE\", \"MSE\", \"RMSE\", \"MAPE\"], \"Résultats\":[mae, mse, rmse, mape]}\n",
    "    df_metrics = pd.DataFrame(dict_metrics)\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrique sur l'échantillon de train validation\n",
    "metrics_regression(y_train, m1_prix_mean)\n",
    "metrics_regression(y_valid, m1_prix_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modele de reg lineaire : selection de variables puis régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "m2_reglin = RFE(regressor, n_features_to_select=25, step=1) # step=1 means removing one feature at each iteration\n",
    "m2_reglin = m2_reglin.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The feature ranking, such that ranking_[i] corresponds to the ranking position of the i-th feature. Selected (i.e., estimated best) features are assigned rank 1.\n",
    "ranking = m2_reglin.ranking_\n",
    "print(ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(m2_reglin.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Variables selectionnees\n",
    "# mask = m2_reglin.support_ == True\n",
    "\n",
    "# # Apply the mask\n",
    "# X_train_df = X_train[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_chap = m2_reglin.predict(X_train)\n",
    "y_valid_chap = m2_reglin.predict(X_valid)\n",
    "\n",
    "RMSE_m2_train = np.sqrt(np.sum((y_train - y_train_chap)**2) / X_train.shape[0])\n",
    "RMSE_m2_valid = np.sqrt(np.sum((y_valid - y_valid_chap)**2) / X_valid.shape[0])\n",
    "\n",
    "print(RMSE_m2_train,RMSE_m2_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrique sur l'échantillon de train validation\n",
    "metrics_regression(y_valid, y_valid_chap)\n",
    "# le MAPE est de 19 % sur le jeu de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphique des prédictions en fonction des valeurs réelles, échantillon de validation\n",
    "df_graph=pd.concat([pd.Series(y_valid),pd.Series(y_valid_chap)], axis=1,sort=False)\n",
    "df_graph.columns=['SalePrice','predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph.plot.scatter(x='SalePrice', y='predictions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(df_graph.SalePrice, df_graph.predictions)\n",
    "ax.plot([df_graph.predictions.min(), df_graph.predictions.max()], [df_graph.predictions.min(), df_graph.predictions.max()], color='r')\n",
    "ax.set(xlabel='SalePrice', ylabel='Prédictions')\n",
    "plt.title(\"Projection des prédictions en fonction des valeurs réelles\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modele de reg lineaire lasso\n",
    "Il s'agit d'une reg lin pénalisée : la fonction de cout est pénalisée afin de pouvoir traiter les var corrélée, le LASSO supprime des variables en les mettant à 0\n",
    "Une régression pénalisée de type ridge (L2) permet de contraindre l'espace des coef estimés pour ne pas qu'ils prennent des valeurs contradictoires et très élevées,\n",
    "Si la régression est de type lasso (L1) alors certains coefficients vont être annulés.\n",
    "Le paramètre alpha contrôle cela : \n",
    "C = regularization strength; must be a positive float = higher values specify stronger regularization.\n",
    "\n",
    "A noter que dans certaines classes, le paramètre est C=1/alpha \n",
    "\n",
    "Tester plusieurs valeurs de alpha 10,25,100 .. et regardez l'impact sur les coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # normalise l’éch d’apprentissage\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_valid_norm= scaler.transform(X_valid)  # applique à l’éch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Modele de reg lineaire lasso avec pénalisation 1/1000\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import linear_model\n",
    "m3_reglinlasso1000=Lasso(alpha = 1000)\n",
    "m3_reglinlasso1000 = m3_reglinlasso1000.fit(X_train_norm, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients du modèle\n",
    "pd.DataFrame({'Coefficients': list(m3_reglinlasso1000.coef_)}, list(X_train.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combien sont nuls sur 233\n",
    "coef=list(m3_reglinlasso1000.coef_)\n",
    "\n",
    "# combien d'élemnts non nuls ?\n",
    "feature_0_1000= list(map(lambda x: x==0.0, coef))\n",
    "feature_non0_1000= list(map(lambda x: x!=0.0, coef))\n",
    "print(\"Coef nuls\",feature_0_1000.count(True)) \n",
    "print(\"% de coef nuls\",feature_0_1000.count(True)/len(coef)*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modele de reg lineaire lasso avec pénalisation 1/1000\n",
    "m3_reglinlasso5000=Lasso(alpha = 5000)\n",
    "m3_reglinlasso5000 = m3_reglinlasso5000.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combien sont nuls sur 233\n",
    "coef=list(m3_reglinlasso5000.coef_)\n",
    "\n",
    "# combien d'élemnts non nuls ?\n",
    "feature_0= list(map(lambda x: x==0.0, coef))\n",
    "print(\"Coef nuls\",feature_0.count(True)) \n",
    "print(\"% de coef nuls\",feature_0.count(True)/len(coef)*100) \n",
    "\n",
    "del feature_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_chap = m3_reglinlasso5000.predict(X_train_norm)\n",
    "y_valid_chap = m3_reglinlasso5000.predict(X_valid_norm)\n",
    "\n",
    "\n",
    "print(\"RMSE Lasso 5000\")\n",
    "\n",
    "# metrique sur l'échantillon de train validation\n",
    "metrics_regression(y_valid, y_valid_chap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_chap = m3_reglinlasso1000.predict(X_train_norm)\n",
    "y_valid_chap = m3_reglinlasso1000.predict(X_valid_norm)\n",
    "\n",
    "\n",
    "print(\"RMSE Lasso 1000\")\n",
    "\n",
    "\n",
    "# metrique sur l'échantillon de train validation\n",
    "metrics_regression(y_valid, y_valid_chap)\n",
    "# le MAPE est de 10 % sur le jeu de validation pour la pénalisation 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(y_valid, y_valid_chap)\n",
    "ax.plot([y_valid_chap.min(), y_valid_chap.max()], [y_valid_chap.min(), y_valid_chap.max()], color='r')\n",
    "ax.set(xlabel='SalePrice', ylabel='Prédictions')\n",
    "plt.title(\"Projection des prédictions en fonction des valeurs réelles\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faites une prédiction pour une nouvelle maison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([numerical_features,categorical_features], axis=1,sort=False)\n",
    "new_house = df_final[df_final['SalePrice'] ==0 ]\n",
    "new_house = new_house.drop(['SalePrice','train','Id'], axis=1).head(1)\n",
    "new_house\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_house_norm= scaler.transform(new_house)\n",
    "\n",
    "prediction = m3_reglinlasso1000.predict(new_house_norm)\n",
    "features = new_house.columns\n",
    "print(\"\\n La valeur prévue pour la maison est: {:,}\".format(round(prediction[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(new_house)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D'autres models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "modele_arbre=DecisionTreeRegressor(random_state = 42, max_depth = 5, min_samples_leaf = 30)\n",
    "modele_arbre.fit(X_train_norm, y_train)\n",
    "y_train_chap = modele_arbre.predict(X_train_norm)\n",
    "y_valid_chap = modele_arbre.predict(X_valid_norm)\n",
    "\n",
    "\n",
    "print(\"RMSE Lasso 5000\")\n",
    "\n",
    "# metrique sur l'échantillon de train validation\n",
    "metrics_regression(y_valid, y_valid_chap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "modele_random_forest=RandomForestRegressor(random_state = 42)\n",
    "modele_random_forest.fit(X_train_norm, y_train)\n",
    "y_train_chap = modele_random_forest.predict(X_train_norm)\n",
    "y_valid_chap = modele_random_forest.predict(X_valid_norm)\n",
    "\n",
    "\n",
    "print(\"RMSE Lasso 5000\")\n",
    "\n",
    "# metrique sur l'échantillon de train validation\n",
    "metrics_regression(y_valid, y_valid_chap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "modele_gradient_boosting = GradientBoostingRegressor(random_state = 42)\n",
    "modele_gradient_boosting.fit(X_train_norm, y_train)\n",
    "y_train_chap = modele_gradient_boosting.predict(X_train_norm)\n",
    "y_valid_chap = modele_gradient_boosting.predict(X_valid_norm)\n",
    "\n",
    "\n",
    "print(\"RMSE Lasso 5000\")\n",
    "\n",
    "# metrique sur l'échantillon de train validation\n",
    "metrics_regression(y_valid, y_valid_chap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "name": "Python_Regression_exemple",
  "notebookId": 1320569712343397
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
