{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP MODELISATION DU CHURN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "\n",
    "1. [Import de la table préparée et Séparation Train / Test](#sect1)\n",
    "2. [Standardisation des variables](#sect2)\n",
    "3. [Modélisation](#sectmodel)\n",
    "  - [Régression pénalisée](#sect41)\n",
    "  - [Régression pénalisée (Elastic Net)](#sect42) **BONUS**\n",
    "  - [Random Forest](#sect43)\n",
    "  - [GBM (Gradient Boosting Machine)](#sect44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score,roc_auc_score,roc_curve,auc\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Chargement des données préparées <a name=\"sect1\" ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repertoire = \"../data\"\n",
    "os.chdir(repertoire)\n",
    "file=open(\"churn_prepared.pydata\",\"rb\")\n",
    "data=pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.drop('Churn?',axis=1)\n",
    "y=data['Churn?'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construire l'échantillon d'apprentissage et de test (vérifier la représentativité du taux de cible) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention il faut respecter la meme selection  test_size=0.3,random_state=42\n",
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standardisation des variables <a name=\"sect2\" ></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appliquer une étape de standardisation des variables sur le train et le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "norm= ...  \n",
    "X_train = ...\n",
    "X_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modélisation <a name=\"sectmodel\" ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import de la fonction de lift à utiliser\n",
    "os.chdir('/home/jupyter/python_ml/modules/')\n",
    "from fonctions_metrics import lift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 PARAMETRER LE MODELE REG PENALISEE <a name=\"sect41\" ></a>\n",
    "Choisir ridge (L2) ou lasso (L1) ou elasticnet, avec la classe LogisticRegression\n",
    "Définir une grille d'hyper param pour C\n",
    "et utliser GridSearchCV pour la balayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regression logistique avec pénalité lasso et grid search\n",
    "#### on cherche par CV le meilleur C (1/alpha) le coef de regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [{\"C\":...}]\n",
    "\n",
    "# Grid Search : on indique le modele et la grille de param\n",
    "modeleLassoCV = GridSearchCV (.... n_jobs=-1,scoring='roc_auc')\n",
    "modeleLassoCV = modeleLassoCV.fit(X_train,y_train)\n",
    "modeleLassoCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je constate que le meilleur modeles est 0.05 donc je réentraine sur le Train avec les meilleurs paramètres \n",
    "model_LogitL1 =LogisticRegression(...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer les coef\n",
    "coef=list(model_LogitL1.coef_[0]) # c un array2d, \n",
    "len(coef) # il y a 20 \n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combien d'élemnts non nuls ?\n",
    "feature_0= [i for i in coef if i==0] #print(feature_0)\n",
    "print(len(feature_0))\n",
    "# PLus on baisse C, plus de colonnes s'annulent (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser les résultats et les performances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction des probabilités de 1 \n",
    "\n",
    "probas_test = ...\n",
    "probas_train = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score: accuracy taux de bien classé global au cutoff de 0.5\n",
    "print(model_LogitL1.score(X_test, y_test))\n",
    "print(model_LogitL1.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC\n",
    "print(roc_auc_score(y_train,probas_train))\n",
    "print(roc_auc_score(y_test,probas_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lift(probas_train,X_train,y_train))\n",
    "print(lift(probas_test,X_test,y_test))\n",
    "\n",
    "# Le lift à 10% : je prend les 10% plus fortes proba de churn (individus les plus risqués),\n",
    "# taux de churn / taux de churn moyen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute lift at 5%\n",
    "print(lift(probas_train,X_train,y_train,p=5))\n",
    "print(lift(probas_test,X_test,y_test,p=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENR LES RESULTATS DANS UN DICTIONNAIRE POUR POUVOIR COMPARER\n",
    "model='Score Lasso'\n",
    "# métriques (liste de dictionnaires)\n",
    "metriques = [{'model':model,'AUC_test':round(roc_auc_score(y_test,probas_test),3),'lift at 5':lift(probas_test,X_test,y_test,p=5),'lift at 10':lift(probas_test,X_test,y_test,p=10)}]\n",
    "metriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat de confusion à un cutoff donné\n",
    "pred_test = (probas_test > 0.14).astype(int)\n",
    "print(confusion_matrix(y_test, pred_test)\n",
    "print(pd.crosstab(y_test,pred_test, normalize=\"index\"))\n",
    "print(pd.crosstab(y_test,pred_test, normalize=\"columns\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Afficher le classification report entre un cutoff donnée (ex : 0,14 et le cutoff par défaut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Fidèles','Churners']\n",
    "\n",
    "# métriques au cutoff donné\n",
    "print(classification_report(... target_names=target_names))\n",
    "# métriques au cutoff par défaut\n",
    "print(classification_report(..., target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 PARAMETRER LE MODELE REG PENALISEE ELASTICNET <a name=\"sect42\" ></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disponible dans le notebook de correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 PARAMETRER LE MODELE RANDOMFOREST <a name=\"sect43\" ></a>\n",
    "Tester un modle light peu profond et un modele complexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_light = RandomForestClassifier(  ...\n",
    "                                     )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_complex= RandomForestClassifier(  ...\n",
    "                                     )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprentissage des modeles sur le train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser les résultats et les performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction des probabilités de 1 \n",
    "probas_test = ...\n",
    "probas_train = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC sur train et test avec roc_auc_score\n",
    "print(roc_auc_score(y_train,probas_train))\n",
    "print(roc_auc_score(y_test,probas_test))\n",
    "# un peu de surapprentissage mais peu ce qui est normal car ce sont des arbres peu profonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lift(probas_train,X_train,y_train))\n",
    "print(lift(probas_test,X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AJOUTE LES RESULTATS\n",
    "model='rf light'\n",
    "# métriques (liste de dictionnaires)\n",
    "metriques.append([{'model':model,'AUC_test':round(roc_auc_score(y_test,probas_test),3),'lift at 5':lift(probas_test,X_test,y_test,p=5),'lift at 10':lift(probas_test,X_test,y_test,p=10)}])\n",
    "metriques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 PARAMETRER LE MODELE GRADIENT BOOSTING MACHINE <a name=\"sect44\" ></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_noRand05=GradientBoostingClassifier(loss='deviance', learning_rate=0.05,\n",
    "                           n_estimators=500,\n",
    "                           subsample=1.0, min_samples_split=20, min_samples_leaf=10,\n",
    "                           max_depth=4,\n",
    "                                       random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprentissage du modele\n",
    "gbt_noRand05.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse du nb iterations optimal en affichant la fonction de perte sur le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter=500\n",
    "iter = np.arange(niter) + 1\n",
    "test_deviance = np.zeros((niter,), dtype=np.float64)\n",
    "# staged_decision_functio : décision fonction à chaque iteration\n",
    "for i, y_pred in enumerate(gbt_noRand05.staged_decision_function(X_test)):\n",
    "    # clf.loss_ assumes that y_test[i] in {0, 1}\n",
    "    test_deviance[i] = gbt_noRand05.loss_(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Erreur sur le test (evolution deviance)\n",
    "plt.plot(iter,test_deviance,label='Test',color='darkorange')\n",
    "        # min vers 100 \n",
    "# Erreur sur apprentissage (evolution deviance)\n",
    "plt.plot(iter,gbt_noRand05.train_score_,label='Apprentissage',color='navy')    \n",
    "# Diminution de l'erreur rapport modele precedant (par rapport au oob)\n",
    "#plt.plot(iter,gbt_noRand05.oob_improvement_)\n",
    "plt.legend(loc=\"upper right\", fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo avec randomisation subsample=0.5 et max_feature = racine(nb variable)\n",
    "\n",
    "gbt_Rand=GradientBoostingClassifier(loss='deviance', learning_rate=0.05,\n",
    "                           n_estimators=500,\n",
    "                           subsample=0.5, min_samples_split=30, min_samples_leaf=20,\n",
    "                           min_weight_fraction_leaf=0.005,\n",
    "                           max_depth=3,max_leaf_nodes=12,max_features=\"sqrt\", random_state=42)\n",
    "# Apprentissage du modele\n",
    "gbt_Rand.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter=500\n",
    "iter = np.arange(niter) + 1\n",
    "test_deviance = np.zeros((niter,), dtype=np.float64)\n",
    "# staged_decision_functio : décision fonction à chaque iteration\n",
    "for i, y_pred in enumerate(gbt_Rand.staged_decision_function(X_test)):\n",
    "    # clf.loss_ assumes that y_test[i] in {0, 1}\n",
    "    test_deviance[i] = gbt_Rand.loss_(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Erreur sur le test (evolution deviance)\n",
    "plt.plot(iter,test_deviance,label='Test',color='darkorange')\n",
    "        # min vers 100 \n",
    "# Erreur sur apprentissage (evolution deviance)\n",
    "plt.plot(iter,gbt_Rand.train_score_,label='Apprentissage',color='navy')    \n",
    "# Diminution de l'erreur rapport modele precedant (par rapport au oob)\n",
    "#plt.plot(iter,gbt_noRand05.oob_improvement_)\n",
    "plt.legend(loc=\"upper right\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo early stopping (150 itération)\n",
    "\n",
    "gbt_Rand150=GradientBoostingClassifier(loss='deviance', learning_rate=0.05,\n",
    "                           n_estimators=150,\n",
    "                           subsample=0.5, min_samples_split=30, min_samples_leaf=20,\n",
    "                           min_weight_fraction_leaf=0.005,\n",
    "                           max_depth=3,max_leaf_nodes=12,max_features=\"sqrt\", random_state=42)\n",
    "# Apprentissage du modele\n",
    "gbt_Rand150.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter=150\n",
    "iter = np.arange(niter) + 1\n",
    "test_deviance = np.zeros((niter,), dtype=np.float64)\n",
    "# staged_decision_functio : décision fonction à chaque iteration\n",
    "for i, y_pred in enumerate(gbt_Rand150.staged_decision_function(X_test)):\n",
    "    # clf.loss_ assumes that y_test[i] in {0, 1}\n",
    "    test_deviance[i] = gbt_Rand150.loss_(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Erreur sur le test (evolution deviance)\n",
    "plt.plot(iter,test_deviance,label='Test',color='darkorange')\n",
    "        # min vers 100 \n",
    "# Erreur sur apprentissage (evolution deviance)\n",
    "plt.plot(iter,gbt_Rand150.train_score_,label='Apprentissage',color='navy')    \n",
    "# Diminution de l'erreur rapport modele precedant (par rapport au oob)\n",
    "#plt.plot(iter,gbt_noRand05.oob_improvement_)\n",
    "plt.legend(loc=\"upper right\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser les résultats et les performances (light) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction des probabilités de 1 , array2d\n",
    "probas_test = gbt_noRand05.predict_proba(X_test)[:,1]\n",
    "probas_train = gbt_noRand05.predict_proba(X_train)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(y_train,probas_train))\n",
    "print(roc_auc_score(y_test,probas_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AJOUTE LES RESULTATS\n",
    "model='gbm no rand'\n",
    "# métriques (liste de dictionnaires)\n",
    "metriques.append([{'model':model,'AUC_test':round(roc_auc_score(y_test,probas_test),3),'lift at 5':lift(probas_test,X_test,y_test,p=5),'lift at 10':lift(probas_test,X_test,y_test,p=10)}])\n",
    "metriques\n",
    "# conclusion  le modele RF est plus predictif mais moins confiance dans sa capacité à etre robuste à moyen terme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction des probabilités de 1 , array2d\n",
    "probas_test = gbt_Rand.predict_proba(X_test)[:,1]\n",
    "probas_train = gbt_Rand.predict_proba(X_train)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(y_train,probas_train))\n",
    "print(roc_auc_score(y_test,probas_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AJOUTE LES RESULTATS\n",
    "model='gbm rand'\n",
    "# métriques (liste de dictionnaires)\n",
    "metriques.append([{'model':model,'AUC_test':round(roc_auc_score(y_test,probas_test),3),'lift at 5':lift(probas_test,X_test,y_test,p=5),'lift at 10':lift(probas_test,X_test,y_test,p=10)}])\n",
    "metriques\n",
    "# conclusion  le modele RF est plus predictif mais moins confiance dans sa capacité à etre robuste à moyen terme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction des probabilités de 1 , array2d\n",
    "probas_test = gbt_Rand150.predict_proba(X_test)[:,1]\n",
    "probas_train = gbt_Rand150.predict_proba(X_train)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(y_train,probas_train))\n",
    "print(roc_auc_score(y_test,probas_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AJOUTE LES RESULTATS\n",
    "model='gbm rand 150'\n",
    "# métriques (liste de dictionnaires)\n",
    "metriques.append([{'model':model,'AUC_test':round(roc_auc_score(y_test,probas_test),3),'lift at 5':lift(probas_test,X_test,y_test,p=5),'lift at 10':lift(probas_test,X_test,y_test,p=10)}])\n",
    "metriques\n",
    "# conclusion  le modele RF est plus predictif mais moins confiance dans sa capacité à etre robuste à moyen terme\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
